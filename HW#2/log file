=== epoch:1, train acc:0.231, test acc:0.268 ===
train loss:2.3004430849897806
train loss:2.270390129235819
train loss:2.1799088416766206
train loss:1.9390829032261963
train loss:1.6746540389096685
train loss:1.3005713429590644
train loss:1.0465433830644948
train loss:0.7844879371232025
train loss:0.652599676984788
train loss:0.5006286133295821
=== epoch:2, train acc:0.819, test acc:0.783 ===
train loss:0.5970782360991602
train loss:0.4213256662079242
train loss:0.49820388895676104
train loss:0.35075564455040625
train loss:0.38362751637240483
train loss:0.3515030201734941
train loss:0.28275253114901866
train loss:0.495806397322708
train loss:0.34103720294092227
train loss:0.28352482050707806
=== epoch:3, train acc:0.886, test acc:0.866 ===
train loss:0.33124673196789794
train loss:0.38106129551191775
train loss:0.4172406451646815
train loss:0.4691962609162822
train loss:0.2575522613282114
train loss:0.3368343282464338
train loss:0.30492497783551187
train loss:0.16855790958163483
train loss:0.27016295981498556
train loss:0.2004853962765611
=== epoch:4, train acc:0.903, test acc:0.895 ===
train loss:0.2419003359819923
train loss:0.23421444278192557
train loss:0.2406941323780864
train loss:0.2263128516894605
train loss:0.16463958847551427
train loss:0.31066041092897234
train loss:0.19595866117794256
train loss:0.27350549107314426
train loss:0.4418761507119802
train loss:0.20038845951664347
=== epoch:5, train acc:0.921, test acc:0.907 ===
train loss:0.222856401166774
train loss:0.19484266932718697
train loss:0.2722945227456149
train loss:0.10768809931012382
train loss:0.10449727783846069
train loss:0.17941206126412154
train loss:0.23611429603237039
train loss:0.20880320646165498
train loss:0.14790776828295826
train loss:0.11169218016801594
=== epoch:6, train acc:0.939, test acc:0.925 ===
train loss:0.20067135448371343
train loss:0.1793538742309511
train loss:0.13484380702645565
train loss:0.24700533291632318
train loss:0.14354095510923426
train loss:0.2638666811029936
train loss:0.17484335217254285
train loss:0.14975761298083343
train loss:0.20654837805169135
train loss:0.11021989935238861
=== epoch:7, train acc:0.946, test acc:0.915 ===
train loss:0.06557238737503228
train loss:0.10671137599528645
train loss:0.12708622592603827
train loss:0.12363336913665575
train loss:0.16038575092079072
train loss:0.12067852005875444
train loss:0.1566927760066392
train loss:0.23333519183251222
train loss:0.1368525979908057
train loss:0.116037955713873
=== epoch:8, train acc:0.95, test acc:0.935 ===
train loss:0.11314653043604778
train loss:0.11164794210096758
train loss:0.19946926480314783
train loss:0.16057558705197983
train loss:0.1002523148759403
train loss:0.09402359832402545
train loss:0.12739436619961178
train loss:0.17063593782032233
train loss:0.0990137799842076
train loss:0.0657079533764959
=== epoch:9, train acc:0.959, test acc:0.93 ===
train loss:0.09503335544895741
train loss:0.10875967284608334
train loss:0.0946585857089686
train loss:0.046899625396442234
train loss:0.06499788180256791
train loss:0.051314647601930864
train loss:0.11007207437236448
train loss:0.0830130557095291
train loss:0.11393436168244384
train loss:0.07354412895107254
=== epoch:10, train acc:0.959, test acc:0.933 ===
train loss:0.17264964626502738
train loss:0.0425618507888973
train loss:0.10617824412703553
train loss:0.12347186015648565
train loss:0.031330922364607744
train loss:0.08192079463188189
train loss:0.13975523273831564
train loss:0.06411463511070524
train loss:0.08635189816190386
train loss:0.09392028020649076
=== epoch:11, train acc:0.966, test acc:0.937 ===
train loss:0.06937675064493531
train loss:0.1293985238183354
train loss:0.12752308731231424
train loss:0.07640682607998545
train loss:0.06962778226545577
train loss:0.02669992982261674
train loss:0.043576531682170266
train loss:0.11733919587717762
train loss:0.09664835127151684
train loss:0.04781147093896124
=== epoch:12, train acc:0.973, test acc:0.951 ===
train loss:0.08416672395455972
train loss:0.09523858519486032
train loss:0.04737984188091685
train loss:0.02447952102341977
train loss:0.05381839869253433
train loss:0.04449507707386039
train loss:0.06247775399994859
train loss:0.06337341041662889
train loss:0.03614816527889493
train loss:0.07358253453187047
=== epoch:13, train acc:0.976, test acc:0.949 ===
train loss:0.07398953271568945
train loss:0.07149211906995538
train loss:0.036899018863061656
train loss:0.042689146769306616
train loss:0.0812784648810947
train loss:0.02201747134770346
train loss:0.039935994619029705
train loss:0.0383761329529404
train loss:0.04330663589079229
train loss:0.07536024111225297
=== epoch:14, train acc:0.978, test acc:0.953 ===
train loss:0.023863146355780927
train loss:0.025083877124587102
train loss:0.08209339660930275
train loss:0.04616147938888781
train loss:0.11792826710524913
train loss:0.021939463828000858
train loss:0.03593164638346305
train loss:0.08454467489461687
train loss:0.05070727616258496
train loss:0.011765596380298003
=== epoch:15, train acc:0.98, test acc:0.953 ===
train loss:0.020038124098704674
train loss:0.047420372792085545
train loss:0.032146164195796516
train loss:0.06739945239523473
train loss:0.03834467130951435
train loss:0.04091879770857747
train loss:0.033142140063374785
train loss:0.09092937055274936
train loss:0.04069107383522428
train loss:0.05812620550703313
=== epoch:16, train acc:0.989, test acc:0.957 ===
train loss:0.051600700688409516
train loss:0.05164825878718629
train loss:0.030968032100505246
train loss:0.055414732294227914
train loss:0.02811577101117441
train loss:0.031762434846761035
train loss:0.019449156404309692
train loss:0.015905098042435256
train loss:0.028403880533470476
train loss:0.009017913903471515
=== epoch:17, train acc:0.99, test acc:0.961 ===
train loss:0.03436927449474257
train loss:0.026518826273350823
train loss:0.011773673135323013
train loss:0.021980246426765434
train loss:0.02906516252699375
train loss:0.022567739803364795
train loss:0.013854104281007943
train loss:0.0302393883331173
train loss:0.018897324051979386
train loss:0.05839605726479293
=== epoch:18, train acc:0.989, test acc:0.954 ===
train loss:0.030711149146074403
train loss:0.035163692932604726
train loss:0.021036924594565257
train loss:0.03128638264352751
train loss:0.03955281021259119
train loss:0.012446284545163394
train loss:0.029812093492426382
train loss:0.0225287519758472
train loss:0.012423503033237318
train loss:0.022755463543735015
=== epoch:19, train acc:0.991, test acc:0.947 ===
train loss:0.008504204705654335
train loss:0.011100671726093829
train loss:0.0286284887325641
train loss:0.01413192588409651
train loss:0.0079322426746172
train loss:0.011802694696948971
train loss:0.006361278570991498
train loss:0.012558695530803615
train loss:0.010453599272954694
train loss:0.021936611474786503
=== epoch:20, train acc:0.997, test acc:0.957 ===
train loss:0.008766014775691958
train loss:0.01612484633121287
train loss:0.017100229003509857
train loss:0.016324224263031012
train loss:0.02564473898697441
train loss:0.01734324959817102
train loss:0.010262121603921166
train loss:0.037321444259865395
train loss:0.01562756572375695
train loss:0.013425652062903002
=============== Final Test Accuracy ===============
train acc:0.9982, test acc:0.96
